#背景
python原生的多线程threading模块由于GIL全局锁的限制，性能极低，有些情况下多线程的性能比单线程串行还要差，难以忍受
查了好多资料，可以通过多进程弥补GIL加/解锁的局限性
	
	库：multiprocessing
#性能对比

前提：4核，16核CPU
日志文件：10G
内存：1G

之所以限制内存，是因为大数据处理过程中要尽量节省内存资源，优化代码结构，否则内存扩容很麻烦。

思路：10G文件按1G内存分块一次读取，进程数约等于核心数

提速的关键是IO的1G瓶颈限制后，每次读取的文件块通过多进程并发处理，从而降低处理的整体时间


结果：

1、如果直接简单粗暴的读取，10G日志文件会撑爆内存，报IO error
2、单核心1G内存，分块耗时统计的总时间为160秒
3、四核心1G内存，耗时45秒，约为1/4，其他消耗为多进程之前消息传递，信息同步的损耗。
4、十六核心1G内存，耗时不到10秒





可以优化的点：
1、Python切分文件没有shell快，还可以再优化2-3s
2、多进程虽然解决了GIL锁的问题，但是同时不同进程负责的文件块之间的数据是不通的，彼此不知道，因此最后统计要额外通过
get方法实现。